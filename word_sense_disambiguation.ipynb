{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff07832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\97263\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\97263\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\97263\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\97263\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab96a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bank', 10), ('deny', 7), ('loan', 2)]\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Converts treebank tags to WordNet tags.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_polysemous_words(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(words)\n",
    "    polysemous_words = []\n",
    "\n",
    "    for word, tag in tagged_words:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag:\n",
    "            synsets = wn.synsets(word, pos=wn_tag)\n",
    "            if len(synsets) > 1:  # 判断是否为多义词\n",
    "                polysemous_words.append((word, len(synsets)))\n",
    "\n",
    "    return polysemous_words\n",
    "\n",
    "# 示例句子\n",
    "sentence = \"The bank can deny the loan.\"\n",
    "polysemous_words = find_polysemous_words(sentence)\n",
    "print(polysemous_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f32b8",
   "metadata": {},
   "source": [
    "# 方法1：基于Lesk算法的简化词义消歧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abc6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sense for 'bank': sloping land (especially the slope beside a body of water)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\97263\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def simplified_lesk(word, sentence):\n",
    "    best_sense = None\n",
    "    max_overlap = 0\n",
    "    context = set(word_tokenize(sentence))\n",
    "    for sense in wn.synsets(word):\n",
    "        signature = set(word_tokenize(sense.definition()))\n",
    "        for example in sense.examples():\n",
    "            signature.union(set(word_tokenize(example)))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    return best_sense\n",
    "\n",
    "# 使用示例\n",
    "sentence = \"The bank of China can deny the loan.\"\n",
    "word = \"bank\"\n",
    "sense = simplified_lesk(word, sentence)\n",
    "print(f\"Best sense for '{word}':\", sense.definition() if sense else \"No sense found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f77dd3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pywsd\n",
      "  Downloading pywsd-1.2.5-py3-none-any.whl (26.9 MB)\n",
      "     ---------------------------------------- 26.9/26.9 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in d:\\toobox\\anaconda\\lib\\site-packages (from pywsd) (3.7)\n",
      "Requirement already satisfied: numpy in d:\\toobox\\anaconda\\lib\\site-packages (from pywsd) (1.21.5)\n",
      "Requirement already satisfied: pandas in d:\\toobox\\anaconda\\lib\\site-packages (from pywsd) (1.3.5)\n",
      "Collecting wn==0.0.23 (from pywsd)\n",
      "  Downloading wn-0.0.23.tar.gz (31.6 MB)\n",
      "     ---------------------------------------- 31.6/31.6 MB 2.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in d:\\toobox\\anaconda\\lib\\site-packages (from pywsd) (1.15.0)\n",
      "Requirement already satisfied: click in d:\\toobox\\anaconda\\lib\\site-packages (from nltk->pywsd) (7.1.2)\n",
      "Requirement already satisfied: joblib in d:\\toobox\\anaconda\\lib\\site-packages (from nltk->pywsd) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\toobox\\anaconda\\lib\\site-packages (from nltk->pywsd) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\toobox\\anaconda\\lib\\site-packages (from nltk->pywsd) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\97263\\appdata\\roaming\\python\\python37\\site-packages (from pandas->pywsd) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\toobox\\anaconda\\lib\\site-packages (from pandas->pywsd) (2022.1)\n",
      "Requirement already satisfied: colorama in d:\\toobox\\anaconda\\lib\\site-packages (from tqdm->nltk->pywsd) (0.4.4)\n",
      "Building wheels for collected packages: wn\n",
      "  Building wheel for wn (setup.py): started\n",
      "  Building wheel for wn (setup.py): finished with status 'done'\n",
      "  Created wheel for wn: filename=wn-0.0.23-py3-none-any.whl size=31792911 sha256=7ef61066099b2043671569e69430152f9fbb9d5b2aff1d703b480a9204d040c6\n",
      "  Stored in directory: c:\\users\\97263\\appdata\\local\\pip\\cache\\wheels\\ec\\47\\17\\409766c99dd470f34c512000b90b83f34747c2c975769654d7\n",
      "Successfully built wn\n",
      "Installing collected packages: wn, pywsd\n",
      "Successfully installed pywsd-1.2.5 wn-0.0.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (d:\\toobox\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (d:\\toobox\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U pywsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6944fa0",
   "metadata": {},
   "source": [
    "# 使用其他包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "326e59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('depository_financial_institution.n.01')\n"
     ]
    }
   ],
   "source": [
    "from pywsd.lesk import simple_lesk\n",
    "sent = 'I went to the bank to deposit my money'\n",
    "ambiguous = 'bank'\n",
    "answer = simple_lesk(sent, ambiguous, pos='r')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbe7f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'went': to be spent or finished\n",
      "'bank': a financial institution that accepts deposits and channels the money into lending activities\n",
      "'deposit': put into a bank account\n",
      "'money': the official currency issued by a government or national bank\n",
      "[('went', 'to be spent or finished'), ('bank', 'a financial institution that accepts deposits and channels the money into lending activities'), ('deposit', 'put into a bank account'), ('money', 'the official currency issued by a government or national bank')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import pos_tag\n",
    "from pywsd.lesk import simple_lesk\n",
    "\n",
    "# 确保已经下载了必要的nltk资源\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Converts treebank tags to WordNet tags.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_polysemous_words(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(words)\n",
    "    polysemous_words = []\n",
    "\n",
    "    for word, tag in tagged_words:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag:\n",
    "            synsets = wn.synsets(word, pos=wn_tag)\n",
    "            if len(synsets) > 1:  # 判断是否为多义词\n",
    "                polysemous_words.append((word, tag, len(synsets)))\n",
    "\n",
    "    return polysemous_words\n",
    "\n",
    "def disambiguate_sentence(sentence):\n",
    "    polysemous_words = find_polysemous_words(sentence)\n",
    "    disambiguated_words = []\n",
    "\n",
    "    for word, tag, _ in polysemous_words:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        meaning = simple_lesk(sentence, word, pos=wn_tag)\n",
    "        if meaning:\n",
    "            disambiguated_words.append((word, meaning.definition()))\n",
    "\n",
    "    return disambiguated_words\n",
    "\n",
    "# 示例句子\n",
    "sentence = \"I went to the bank to deposit my money\"\n",
    "disambiguated_words = disambiguate_sentence(sentence)\n",
    "for word, meaning in disambiguated_words:\n",
    "    print(f\"'{word}': {meaning}\")\n",
    "\n",
    "    \n",
    "print(disambiguated_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc4dc5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sense for 'bank': a financial institution that accepts deposits and channels the money into lending activities\n",
      "Examples: ['he cashed a check at the bank', 'that bank holds the mortgage on my home']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank to deposit my money.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# 使用simple_lesk进行词义消歧\n",
    "disambiguated = simple_lesk(sentence, word,pos=\"n\")\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Best sense for '{word}':\", disambiguated.definition())\n",
    "if disambiguated.examples():\n",
    "    print(\"Examples:\", disambiguated.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03161355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Toobox\\Anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4d281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
